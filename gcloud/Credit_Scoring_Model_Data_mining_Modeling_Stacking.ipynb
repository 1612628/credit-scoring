{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHUfGmRnQugN"
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yX1QXnBWNtQV",
    "outputId": "b09784e1-eadb-4541-c4b6-f0064e2353cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.18.4)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22->imbalanced-learn) (2.0.0)\n",
      "Requirement already up-to-date: attrdict in /opt/conda/lib/python3.7/site-packages (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from attrdict) (1.14.0)\n",
      "Requirement already up-to-date: click in /opt/conda/lib/python3.7/site-packages (7.1.2)\n",
      "Requirement already up-to-date: lightgbm in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /opt/conda/lib/python3.7/site-packages (from lightgbm) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.18.4)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->lightgbm) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->lightgbm) (2.0.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 4.5 MB/s eta 0:00:01\n",
      "\u001b[31mERROR: feature-engine 0.4.2 has requirement scikit-learn<0.23.0,>=0.22.2, but you'll have scikit-learn 0.23.1 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.4\n",
      "    Uninstalling numpy-1.18.4:\n",
      "      Successfully uninstalled numpy-1.18.4\n",
      "Successfully installed numpy-1.18.5\n",
      "Requirement already up-to-date: scikit-learn in /opt/conda/lib/python3.7/site-packages (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.4.1)\n",
      "Processing ./.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653/PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.3\n",
      "\u001b[31mERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.1.1-py3-none-manylinux2010_x86_64.whl (127.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 127.6 MB 20 kB/s /s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 1.1.0\n",
      "    Uninstalling xgboost-1.1.0:\n",
      "      Successfully uninstalled xgboost-1.1.0\n",
      "Successfully installed xgboost-1.1.1\n",
      "Collecting catboost\n",
      "  Downloading catboost-0.23.2-cp37-none-manylinux1_x86_64.whl (64.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 64.7 MB 52 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from catboost) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /opt/conda/lib/python3.7/site-packages (from catboost) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /opt/conda/lib/python3.7/site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: graphviz in /opt/conda/lib/python3.7/site-packages (from catboost) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: plotly in /opt/conda/lib/python3.7/site-packages (from catboost) (4.5.4)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from catboost) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from catboost) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (46.0.0.post20200311)\n",
      "Installing collected packages: catboost\n",
      "  Attempting uninstall: catboost\n",
      "    Found existing installation: catboost 0.23.1\n",
      "    Uninstalling catboost-0.23.1:\n",
      "      Successfully uninstalled catboost-0.23.1\n",
      "Successfully installed catboost-0.23.2\n",
      "Requirement already up-to-date: scikit-optimize in /opt/conda/lib/python3.7/site-packages (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.0 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: pyaml>=16.9 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize) (20.3.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->scikit-optimize) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /opt/conda/lib/python3.7/site-packages (from pyaml>=16.9->scikit-optimize) (5.3)\n",
      "Requirement already up-to-date: keras in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: ngboost in /opt/conda/lib/python3.7/site-packages (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.7/site-packages (from ngboost) (1.4.1)\n",
      "Requirement already satisfied: lifelines>=0.22.8 in /opt/conda/lib/python3.7/site-packages (from ngboost) (0.24.4)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/conda/lib/python3.7/site-packages (from ngboost) (4.43.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from ngboost) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from ngboost) (0.23.1)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /opt/conda/lib/python3.7/site-packages (from lifelines>=0.22.8->ngboost) (3.2.0)\n",
      "Requirement already satisfied: autograd>=1.3 in /opt/conda/lib/python3.7/site-packages (from lifelines>=0.22.8->ngboost) (1.3)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from lifelines>=0.22.8->ngboost) (1.0.3)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /opt/conda/lib/python3.7/site-packages (from lifelines>=0.22.8->ngboost) (0.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->ngboost) (2.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->ngboost) (0.14.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->lifelines>=0.22.8->ngboost) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->lifelines>=0.22.8->ngboost) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->lifelines>=0.22.8->ngboost) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->lifelines>=0.22.8->ngboost) (0.10.0)\n",
      "Requirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.7/site-packages (from autograd>=1.3->lifelines>=0.22.8->ngboost) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.0->lifelines>=0.22.8->ngboost) (2019.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.0->lifelines>=0.22.8->ngboost) (46.0.0.post20200311)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib>=3.0->lifelines>=0.22.8->ngboost) (1.14.0)\n",
      "Requirement already satisfied: tensorflow==1.14 in /opt/conda/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.34.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.2.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (3.11.4)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.24.3)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.12.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.18.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.0.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.14) (46.0.0.post20200311)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "# Install essential library\n",
    "!pip3 install -U imbalanced-learn\n",
    "!pip3 install attrdict --upgrade\n",
    "!pip3 install click --upgrade\n",
    "!pip3 install lightgbm --upgrade\n",
    "!pip3 install numpy --upgrade\n",
    "!pip3 install scikit-learn --upgrade\n",
    "!pip3 install pyyaml --upgrade\n",
    "!pip3 install xgboost --upgrade\n",
    "!pip3 install catboost --upgrade\n",
    "!pip3 install scikit-optimize --upgrade\n",
    "!pip3 install keras --upgrade\n",
    "!pip3 install ngboost\n",
    "!pip3 install tensorflow==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "ngBIjslG7whD",
    "outputId": "9fb64b3e-0973-42d8-e15e-2303318f1da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-autotime in /opt/conda/lib/python3.7/site-packages (0.1)\n"
     ]
    }
   ],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Garbage collector\n",
    "import gc\n",
    "\n",
    "!pip3 install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RljalvFnQt2w",
    "outputId": "eb1f17d4-0a3d-4d38-e4ad-a42f198e9244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 845 ms\n"
     ]
    }
   ],
   "source": [
    "from scipy import interp\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc, plot_roc_curve, brier_score_loss\n",
    "\n",
    "########################### ROC AUC #############################\n",
    "def cross_validate_auc(model_base, kfold, features=None, evaluate = False, nn_validate=False, **clf_params):\n",
    "  train_tprs = []\n",
    "  train_aucs = []\n",
    "  train_mean_fpr = np.linspace(0, 1, 100)\n",
    "  dev_tprs = []\n",
    "  dev_aucs = []\n",
    "  dev_mean_fpr = np.linspace(0, 1, 100)\n",
    "  fitted_models = []\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  fig.set_size_inches((16,10))\n",
    "  print(\"Cross Validation: ROC AUC score\")\n",
    "  for i in range(0, len(kfold)):\n",
    "    print(\"{}/{}\".format(i+1, len(kfold)))\n",
    "    kf = kfold[i]\n",
    "    X_train_kf, y_train_kf = kf[\"X_train\"].copy(), kf[\"y_train\"].copy()\n",
    "    X_dev_kf, y_dev_kf = kf[\"X_dev\"].copy(), kf[\"y_dev\"].copy()\n",
    "    if features is not None:\n",
    "      X_train_kf = X_train_kf[features]\n",
    "      X_dev_kf = X_dev_kf[features]\n",
    "\n",
    "    model = clone(model_base)\n",
    "    \n",
    "    if nn_validate == True:\n",
    "      model.fit(X_train_kf, y_train_kf, validation_data=(X_dev_kf, y_dev_kf))\n",
    "    elif evaluate == False:\n",
    "      model.fit(X_train_kf, y_train_kf, **clf_params)\n",
    "    else:\n",
    "      model.fit(X_train_kf, y_train_kf, eval_set=[(X_dev_kf, y_dev_kf)],**clf_params)\n",
    "    fitted_models.append(model)\n",
    "    # plot train\n",
    "    train_display = plot_roc_curve(model, X_train_kf, y_train_kf,\n",
    "                         name='Train ROC fold {}'.format(i),\n",
    "                         alpha=0.6, lw=1, ax=ax)\n",
    "    train_interp_tpr = interp(train_mean_fpr, train_display.fpr, train_display.tpr)\n",
    "    train_interp_tpr[0] = 0.0\n",
    "    train_tprs.append(train_interp_tpr)\n",
    "    train_aucs.append(train_display.roc_auc)\n",
    "    # plot dev\n",
    "    dev_display = plot_roc_curve(model, X_dev_kf, y_dev_kf,\n",
    "                         name='Dev ROC fold {}'.format(i),\n",
    "                         alpha=0.6, lw=1, ax=ax)\n",
    "    dev_interp_tpr = interp(dev_mean_fpr, dev_display.fpr, dev_display.tpr)\n",
    "    dev_interp_tpr[0] = 0.0\n",
    "    dev_tprs.append(dev_interp_tpr)\n",
    "    dev_aucs.append(dev_display.roc_auc)\n",
    "  \n",
    "  # plot mean train\n",
    "  train_mean_tpr = np.mean(train_tprs, axis=0)\n",
    "  train_mean_tpr[-1] = 1.0\n",
    "  train_mean_auc = auc(train_mean_fpr, train_mean_tpr)\n",
    "  train_std_auc = np.std(train_aucs)\n",
    "  ax.plot(train_mean_fpr, train_mean_tpr, color='r',\n",
    "        label=r'Train Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (train_mean_auc, train_std_auc),\n",
    "        lw=2, alpha=1)\n",
    "  # plot mean dev\n",
    "  dev_mean_tpr = np.mean(dev_tprs, axis=0)\n",
    "  dev_mean_tpr[-1] = 1.0\n",
    "  dev_mean_auc = auc(dev_mean_fpr, dev_mean_tpr)\n",
    "  dev_std_auc = np.std(dev_aucs)\n",
    "  ax.plot(dev_mean_fpr, dev_mean_tpr, color='b',\n",
    "        label=r'Dev Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (dev_mean_auc, dev_std_auc),\n",
    "        lw=2, alpha=1)\n",
    "  \n",
    "  ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic example\")\n",
    "  ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "  plt.show()\n",
    "\n",
    "  return train_mean_auc, dev_mean_auc, fitted_models\n",
    "\n",
    "########################### Brier score #############################\n",
    "def cross_validate_brier(model_base, kfold, features=None, **clf_params):\n",
    "  train_briers = []\n",
    "  dev_briers = []\n",
    "  fitted_models = []\n",
    "\n",
    "  print(\"Cross Validation: Brier score\")\n",
    "  for i in range(0, len(kfold)):\n",
    "    print(\"{}/{}\".format(i+1, len(kfold)))\n",
    "    kf = kfold[i]\n",
    "    X_train_kf, y_train_kf = kf[\"X_train\"].copy(), kf[\"y_train\"].copy()\n",
    "    X_dev_kf, y_dev_kf = kf[\"X_dev\"].copy(), kf[\"y_dev\"].copy()\n",
    "    if features is not None:\n",
    "      X_train_kf = X_train_kf[features]\n",
    "      X_dev_kf = X_dev_kf[features]\n",
    "\n",
    "    model = clone(model_base)\n",
    "    model.fit(X_train_kf, y_train_kf, **clf_params)\n",
    "    fitted_models.append(model)\n",
    "    # plot train\n",
    "    train_brier = brier_score_loss(y_train_kf, model.predict_proba(X_train_kf)[:,1])\n",
    "    train_briers.append(train_brier)\n",
    "    # plot dev\n",
    "    dev_brier = brier_score_loss(y_dev_kf, model.predict_proba(X_dev_kf)[:,1])\n",
    "    dev_briers.append(dev_brier)\n",
    "  \n",
    "  train_mean_brier = np.mean(train_briers)\n",
    "  train_std_brier = np.std(train_briers)\n",
    "  print(\"----------- Train Brier Score ----------\")\n",
    "  print(train_briers)\n",
    "  print(\"Mean Brier: \", train_mean_brier)\n",
    "\n",
    "  dev_mean_brier = np.mean(dev_briers)\n",
    "  dev_std_brier = np.std(dev_briers)\n",
    "  print(\"----------- Dev Brier Score ----------\")\n",
    "  print(dev_briers)\n",
    "  print(\"Mean Brier: \", dev_mean_brier)\n",
    "\n",
    "  return train_mean_brier, dev_mean_brier, fitted_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKi793QqHcpe"
   },
   "source": [
    "# Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "j9pcQYC7GOYT",
    "outputId": "5ec34bd6-5c9d-40e8-9b99-c2c53141fa81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55.7 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "kfold = []\n",
    "for i in range(0,5):\n",
    "  X_train = pd.read_csv(\"./cv_input/X_train_preprocessed_{}.csv\".format(i + 1))\n",
    "  y_train = pd.read_csv(\"./cv_input/y_train_{}.csv\".format(i + 1))\n",
    "  X_dev = pd.read_csv(\"./cv_input/X_dev_preprocessed_{}.csv\".format(i + 1))\n",
    "  y_dev = pd.read_csv(\"./cv_input/y_dev_{}.csv\".format(i + 1))\n",
    "  X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "  X_dev = pd.DataFrame(scaler.transform(X_dev), columns = X_dev.columns)\n",
    "  kfold.append({\n",
    "      \"X_train\": X_train,\n",
    "      \"y_train\": y_train['label'],\n",
    "      \"X_dev\": X_dev,\n",
    "      \"y_dev\": y_dev['label'],\n",
    "  })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vFIqNieeHcdE",
    "outputId": "a46202c0-2d53-4621-d2e0-994d2ff5a530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 681 ms\n"
     ]
    }
   ],
   "source": [
    "duplicates = []\n",
    "for i in range(5):\n",
    "  duplicate = []\n",
    "  for col in kfold[i]['X_train']:\n",
    "    if col.find('.1') != -1:\n",
    "      duplicate.append(col)\n",
    "  duplicates.append(duplicate)\n",
    "\n",
    "for i in range(5):\n",
    "  kfold[i]['X_train'] = kfold[i]['X_train'].drop(columns=duplicates[i])\n",
    "  kfold[i]['X_dev'] = kfold[i]['X_dev'].drop(columns=duplicates[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "NDlp9v1HpCNr",
    "outputId": "8777f8d5-a58f-4117-8f00-66e6fd4fcd85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 1392)\n",
      "(6000, 1392)\n",
      "(24000, 1381)\n",
      "(6000, 1381)\n",
      "(24000, 1444)\n",
      "(6000, 1444)\n",
      "(24000, 1409)\n",
      "(6000, 1409)\n",
      "(24000, 1403)\n",
      "(6000, 1403)\n",
      "time: 1.12 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "  print(kfold[i]['X_train'].shape)\n",
    "  print(kfold[i]['X_dev'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SbX2hZ1UOSTp",
    "outputId": "5bd512e2-ec08-4fe2-8f02-e7b6b380e6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.12 ms\n"
     ]
    }
   ],
   "source": [
    "# Covariate shilt\n",
    "dropped_cols = ['FIELD_3',\n",
    " 'stats_mean_FIELD_10_incomplete',\n",
    " 'stats_mean_FIELD_8_FIELD_55',\n",
    " 'FIELD_3',\n",
    " 'stats_mean_FIELD_8_FIELD_4',\n",
    " 'FIELD_3',\n",
    " 'stats_mean_FIELD_44_FIELD_4',\n",
    " 'FIELD_3',\n",
    " 'stats_mean_FIELD_8_FIELD_57',\n",
    " 'stats_mean_FIELD_10_incomplete',\n",
    " 'stats_mean_FIELD_35_FIELD_57',\n",
    " 'FIELD_3',\n",
    " 'stats_mean_FIELD_8_FIELD_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SKfjV5OoTGDG",
    "outputId": "9d8f1a8e-ea62-4543-b20c-586ee952c2d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 549 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    fold_features = list(set(kfold[i]['X_train'].columns) - set(dropped_cols))\n",
    "    kfold[i]['X_train'] = kfold[i]['X_train'][fold_features]\n",
    "    kfold[i]['X_dev'] = kfold[i]['X_dev'][fold_features]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-90ac69cd16b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{i+1}/5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mrfecv_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mrfecv_feas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrfecv_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mselected_feas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfecv_feas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    550\u001b[0m         scores = parallel(\n\u001b[1;32m    551\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    550\u001b[0m         scores = parallel(\n\u001b[1;32m    551\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     return rfe._fit(\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    803\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    806\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    598\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "params = {\n",
    "  'boosting_type': 'goss',\n",
    "  'objective': 'binary',\n",
    "  'n_estimators': 1000,\n",
    "  'num_leaves': 15,\n",
    "  'max_depth': 18,\n",
    "#   'subsample_for_bin': 512,\n",
    "  'learning_rate': 0.001,\n",
    "  # 'min_child_samples': 100,\n",
    "  'subsample_freq': 1,\n",
    "  'subsample': 1.,\n",
    "  'colsample_bytree': 0.01,\n",
    "  'reg_alpha': 50.0,\n",
    "  'reg_lambda': 50.0,\n",
    "  'random_state':42,\n",
    "  'verbose':0\n",
    "}\n",
    "\n",
    "lgm = LGBMClassifier(**params)\n",
    "rfecv_ = RFECV(estimator=lgm, step=10, cv=2, scoring='roc_auc', min_features_to_select=100, verbose=0)\n",
    "selected_feas = []\n",
    "for i in range(0,5):\n",
    "    print(f'{i+1}/5')\n",
    "    rfecv_.fit(kfold[i]['X_train'], kfold[i]['y_train'])\n",
    "    rfecv_feas = set(kfold[i]['X_train'].columns[rfecv_.support_])\n",
    "    selected_feas.append(rfecv_feas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(f'{i+1}/5')\n",
    "    print(len(selected_feas[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(f'{i+1}/5')\n",
    "    print(len(selected_feas[i]))\n",
    "    kfold[i]['X_train'] = kfold[i]['X_train'][selected_feas[i]]\n",
    "    kfold[i]['X_dev'] = kfold[i]['X_dev'][selected_feas[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBYSC-2cQzqm"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zcGlbbd0WHUW"
   },
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7oiu2vgWQ5L1",
    "outputId": "0c92da1b-d01a-4775-9762-5264932b7552"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "params = {\n",
    "  'boosting_type': 'goss',\n",
    "  'objective': 'binary',\n",
    "  'n_estimators': 1000,\n",
    "  'num_leaves': 15,\n",
    "  'max_depth': 18,\n",
    "#   'subsample_for_bin': 512,\n",
    "  'learning_rate': 0.001,\n",
    "  # 'min_child_samples': 100,\n",
    "  'subsample_freq': 1,\n",
    "  'subsample': 1.,\n",
    "  'colsample_bytree': 0.01,\n",
    "  'reg_alpha': 50.0,\n",
    "  'reg_lambda': 50.0,\n",
    "  'random_state':42\n",
    "}\n",
    "fit_params={\n",
    "  'early_stopping_rounds': 50,\n",
    "  'eval_metric': 'logloss',\n",
    "  'verbose': False\n",
    "}\n",
    "\n",
    "lgm = LGBMClassifier(**params)\n",
    "cross_validate_auc(lgm, kfold, features=None, evaluate=True, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2jjqhdCWJNe"
   },
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GWjy2lFiWGSg",
    "outputId": "9c1cf5d8-e8a8-4dd4-e5b9-4fb992b5f25b"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "params={\n",
    "  # 'grow_policy':'Depthwise',\n",
    "  'loss_function': 'Logloss',\n",
    "  'eval_metric': 'AUC',\n",
    "  'iterations': 1000,\n",
    "  'learning_rate': 0.001,\n",
    "  'depth': 16,\n",
    "  'l2_leaf_reg': 50.0,\n",
    "  # 'max_bin': 127,\n",
    "  'colsample_bylevel': 0.01,\n",
    "  'od_type': 'Iter',\n",
    "  'od_wait': 50,\n",
    "}\n",
    "fit_params={\n",
    "  'early_stopping_rounds': 50,\n",
    "  'verbose':False\n",
    "}\n",
    "\n",
    "cat = CatBoostClassifier(**params)\n",
    "cross_validate_auc(cat, kfold, features=None, evaluate=True, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZbcYYTDYZwu"
   },
   "source": [
    "# NG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GiDWIAJPYY6x",
    "outputId": "cdde8442-de4b-49aa-c199-ff83a5b88491"
   },
   "outputs": [],
   "source": [
    "from ngboost import NGBClassifier\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class MyNGBClassifier(NGBClassifier, ClassifierMixin):\n",
    "  def fit(self, X, y):\n",
    "    if type(X) != np.ndarray:\n",
    "      X_np = X.to_numpy()\n",
    "    else:\n",
    "      X_np = X.copy()\n",
    "    y_np = y.copy()\n",
    "    if type(y) == pd.Series:\n",
    "      y_np = y.astype(\"int64\").to_numpy()\n",
    "    self.classes_ = unique_labels(y)\n",
    "    return super().fit(X_np, y_np)\n",
    "  \n",
    "  def predict(self, X):\n",
    "    if type(X) != np.ndarray:\n",
    "      X_np = X.to_numpy()\n",
    "    else:\n",
    "      X_np = X.copy()\n",
    "    return super().predict(X_np)\n",
    "\n",
    "  def predict_proba(self, X):\n",
    "    if type(X) != np.ndarray:\n",
    "      X_np = X.to_numpy()\n",
    "    else:\n",
    "      X_np = X.copy()\n",
    "    return super().predict_proba(X_np)\n",
    "  \n",
    "\n",
    "ngb_clf = MyNGBClassifier(n_estimators=250, random_state=42)\n",
    "cross_validate_auc(ngb_clf, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jB2i5bVXawd"
   },
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kLvQaSTSYz5c",
    "outputId": "d7c6b19a-1255-4d1c-d8a5-c317cd0e549a"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "class NeuralNetwork(BaseEstimator, ClassifierMixin):\n",
    "  \n",
    "  def __init__(self, architecture_config, training_config, callbacks_config):\n",
    "    # logger.info('initializing NeuralNetwork ...')\n",
    "    self.architecture_config_ = architecture_config\n",
    "    self.model_params_ = architecture_config['model_params']\n",
    "    self.optimizer_params_ = architecture_config['optimizer_params']\n",
    "    self.training_config_ = training_config\n",
    "    self.callbacks_config_ = callbacks_config\n",
    "    self.classes_ = np.array([0,1])\n",
    "\n",
    "  def get_params(self, deep=True):\n",
    "    return {'architecture_config': self.architecture_config_,\n",
    "            'training_config': self.training_config_,\n",
    "            'callbacks_config': self.callbacks_config_\n",
    "            }\n",
    "    \n",
    "  def _build_optimizer(self, **kwargs):\n",
    "    return Adam(**self.optimizer_params_)\n",
    "  \n",
    "  def _build_loss(self, **kwargs):\n",
    "    return 'binary_crossentropy'\n",
    "\n",
    "  def _build_callbacks(self):\n",
    "    callbacks = []\n",
    "    for callback_config in self.callbacks_config_:\n",
    "      if callback_config == 'EarlyStopping':\n",
    "        callbacks.append(\n",
    "            EarlyStopping(\n",
    "                **self.callbacks_config_[callback_config]\n",
    "            )\n",
    "        )\n",
    "      elif callback_config == 'ModelCheckpoint':\n",
    "        callbacks.append(\n",
    "            ModelCheckpoint(\n",
    "                **self.callbacks_config_[callback_config]\n",
    "            )\n",
    "        )\n",
    "      \n",
    "    return callbacks\n",
    "\n",
    "  def _build_model(self, input_shape, **kwargs):\n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "    for layer in range(self.model_params_['layers']):\n",
    "      config = {key: val[layer] for key, val in self.model_params_.items() if key != 'layers'}\n",
    "      if layer == 0:\n",
    "        model.add(Dense(config['neurons'],\n",
    "                        kernel_regularizer=l1_l2(l1=float(config['l1']), l2=float(config['l2'])),\n",
    "                        input_shape=input_shape\n",
    "                        ))\n",
    "      else:\n",
    "        model.add(Dense(config['neurons'],\n",
    "                        kernel_regularizer=l1_l2(l1=config['l1'], l2=config['l2'])\n",
    "                        ))\n",
    "      if config['batch_norm']:\n",
    "        model.add(BatchNormalization())\n",
    "      model.add(Activation(config['activation']))\n",
    "      model.add(Dropout(config['dropout']))\n",
    "    \n",
    "    return model\n",
    "  \n",
    "  def _compile_model(self, input_shape):\n",
    "    model = self._build_model(input_shape)\n",
    "    optimizer = self._build_optimizer()\n",
    "    loss = self._build_loss()\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    return model\n",
    "  \n",
    "  def fit(self, X, y, validation_data=None, *args, **kwargs):\n",
    "    # logger.info(f'Neural network, fit') \n",
    "    # logger.info(f'Neural network, training data shape {X.shape}')\n",
    "    # logger.info(f'Neural network, training label shape {y.shape}')\n",
    "    print(Counter(y))\n",
    "    self.model = self._compile_model(input_shape=(X.shape[1], ))\n",
    "    \n",
    "    self.callbacks = self._build_callbacks()\n",
    "    \n",
    "    self.model.fit(X,\n",
    "                    y,\n",
    "                    validation_data=validation_data,\n",
    "                    verbose=1,\n",
    "                    **self.training_config_,\n",
    "                    callbacks=self.callbacks)\n",
    "    # logger.info(f'Neural network, done fit') \n",
    "    return self\n",
    "  \n",
    "  def score(self, X, y, *args, **kwargs):\n",
    "    return roc_auc_score(y, self.transform(X)) \n",
    "\n",
    "  def transform(self, X, *args, **kwargs):\n",
    "    # logger.info(f'Neural network, transform') \n",
    "    # logger.info(f'Neural network, transform, testing shape: {X.shape}')\n",
    "    pred = self.model.predict(X, verbose=1)\n",
    "    pred = np.array([x[0] for x in pred]).reshape(-1)\n",
    "    # logger.info(f'Neural network, transform, predictions shape: {pred.shape}')\n",
    "    # logger.info(f'Neural network, done transform') \n",
    "    return pred\n",
    "  \n",
    "  def predict_proba(self, X, *args, **kwargs):\n",
    "    # logger.info(f'Neural network, predict_proba') \n",
    "    # logger.info(f'Neural network, predict_proba, testing shape: {X.shape}')\n",
    "    pred = self.model.predict(X, verbose=1).reshape(-1)\n",
    "    pred = np.hstack((np.zeros(pred.shape[0]).reshape(-1), pred)).reshape(-1, 2)\n",
    "    # logger.info(f'Neural network, predict_proba, done') \n",
    "    return pred\n",
    "\n",
    "params = {\n",
    "        'architecture_config': {\n",
    "            'model_params': {\n",
    "                'layers': 3,\n",
    "                'neurons': [128, 32, 1],\n",
    "                'activation': [\"relu\",\"relu\", \"sigmoid\"],\n",
    "                'dropout': [0.3, 0.3, 0.],\n",
    "                'batch_norm': [True, False, False],\n",
    "                'l1': [2., 0., 0.],\n",
    "                'l2': [3., 0., 0.]\n",
    "            },\n",
    "            'optimizer_params': {\n",
    "                'learning_rate': 0.01,\n",
    "                'beta_1': 0.9,\n",
    "                'beta_2': 0.99\n",
    "            }\n",
    "        },\n",
    "        'training_config': {\n",
    "            'epochs': 10,\n",
    "            'batch_size': 512\n",
    "        },\n",
    "        'callbacks_config': {\n",
    "            # 'EarlyStopping':{\n",
    "            #     'monitor':'loss',\n",
    "            #     'patience':30,\n",
    "            #     'mode':'min'\n",
    "            #     },\n",
    "        },\n",
    "    }\n",
    "\n",
    "nn = NeuralNetwork(**params)\n",
    "\n",
    "\n",
    "sm = SMOTE(sampling_strategy = 0.1, random_state=31)\n",
    "kfold_nn = []\n",
    "for i in range(5):\n",
    "  X_train_new, y_train_new = sm.fit_resample(kfold[i]['X_train'], kfold[i]['y_train'])\n",
    "  X_train_new = pd.DataFrame(X_train_new, columns=kfold[i]['X_train'].columns)\n",
    "  kfold_nn.append({\n",
    "      'X_train':X_train_new,\n",
    "      'X_dev':kfold[i]['X_dev'],\n",
    "      'y_train':y_train_new,\n",
    "      'y_dev': kfold[i]['y_dev']\n",
    "      })\n",
    "cross_validate_auc(nn, kfold, nn_validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rEbm32ffH4B"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 948
    },
    "colab_type": "code",
    "id": "u-WwG-lK-gQx",
    "outputId": "a02c79d5-3fd2-4f5e-c054-e40fcf372d8a"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "params={\n",
    "  'penalty': 'elasticnet',\n",
    "  'tol': 1e-3,\n",
    "  'C': 5,\n",
    "  'fit_intercept': True,\n",
    "  # 'class_weight': 'balanced',\n",
    "  'solver': 'saga',\n",
    "  'max_iter': 100,\n",
    "  'l1_ratio':0\n",
    "}\n",
    "\n",
    "logit = LogisticRegression(**params)\n",
    "cross_validate_auc(logit, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoRjS7wqW5K0"
   },
   "source": [
    "# Deep Neural Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FKKPZUvW4t0"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "# from functools import reduce\n",
    "\n",
    "\n",
    "# def tf_kron_prod(a, b):\n",
    "#     res = tf.einsum('ij,ik->ijk', a, b)\n",
    "#     res = tf.reshape(res, [-1, tf.reduce_prod(res.shape[1:])])\n",
    "#     return res\n",
    "\n",
    "\n",
    "# def tf_bin(x, cut_points, temperature=0.1):\n",
    "#     # x is a N-by-1 matrix (column vector)\n",
    "#     # cut_points is a D-dim vector (D is the number of cut-points)\n",
    "#     # this function produces a N-by-(D+1) matrix, each row has only one element being one and the rest are all zeros\n",
    "#     D = cut_points.get_shape().as_list()[0]\n",
    "#     W = tf.reshape(tf.linspace(1.0, D + 1.0, D + 1), [1, -1])\n",
    "#     cut_points = tf.contrib.framework.sort(cut_points)  # make sure cut_points is monotonically increasing\n",
    "#     b = tf.cumsum(tf.concat([tf.constant(0.0, shape=[1]), -cut_points], 0))\n",
    "#     h = tf.matmul(x, W) + b\n",
    "#     res = tf.nn.softmax(h / temperature)\n",
    "#     return res\n",
    "\n",
    "\n",
    "# def nn_decision_tree(x, cut_points_list, leaf_score, temperature=0.1):\n",
    "#     # cut_points_list contains the cut_points for each dimension of feature\n",
    "#     leaf = reduce(tf_kron_prod,\n",
    "#                   map(lambda z: tf_bin(x[:, z[0]:z[0] + 1], z[1], temperature), enumerate(cut_points_list)))\n",
    "#     return tf.matmul(leaf, leaf_score)\n",
    "  \n",
    "# for i in range(0,5):\n",
    "#     X_train, X_dev = kfold[i]['X_train'], kfold[i]['X_dev']\n",
    "#     y_train, y_dev = kfold[i]['y_train'], kfold[i]['y_dev']\n",
    "    \n",
    "#     d = X_train.shape[1]\n",
    "#     num_cut = [1]*X_train.shape[1]\n",
    "#     num_leaf = np.prod(np.array(num_cut) + 1)\n",
    "#     num_class = 2\n",
    "#     sess= tf.InteractiveSession()\n",
    "   \n",
    "#     x_ph = tf.placeholder(tf.float32, [None, d])\n",
    "#     y_ph = tf.placeholder(tf.float32, [None, num_class])\n",
    "#     cut_points_list = [tf.Variable(tf.random_uniform([i])) for i in num_cut]\n",
    "#     leaf_score = tf.Variable(tf.random_uniform([num_leaf, num_class]))\n",
    "#     y_pred = nn_decision_tree(x_ph, cut_points_list, leaf_score, temperature=0.01)\n",
    "#     loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(logits=y_pred, onehot_labels=y_ph))\n",
    "#     opt = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "        \n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     for i in range(100):\n",
    "#         _ , loss_e = sess.run([opt, loss], feed_dict={x_ph: X_train, y_ph: y_train})\n",
    "#         if i%10 == 0:\n",
    "#             print(loss_e)\n",
    "#     print(f'error rate {1 - np.mean(np.argmax(y_pred.eval(feed_dict={x_ph: X_train}), axis=1) == np.argmax(y_train, axis=1))}')\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Credit Scoring Model - Data mining - Modeling Stacking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
