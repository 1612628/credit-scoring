parameters:
# Data
  train_filepath: './input/train_input_imputed.csv'
  test_filepath: './input/test_input_imputed.csv'
  first_level_oof_predictions_dir: './models/stacking_1/oof'
  experiment_dir: './models/stacking_1/exp'
# Data preparation
  n_cv_splits: 5
  dev_size: 0.2
  stratified_cv: True
  shuffle: True
  hyperparameter_search__method: None
  hyperparameter_search__runs: 0

# Excution
  clean_experiment_directory_before_training: 1
  num_workers: 8
  verbose: 1
  callbacks_on: 1

# Preprocessing
  fill_missing: False
  fill_value: 0

# Feature extraction
  use_nan_count: True

# Feature selection
  use_train: True

# Light GBM
  lgbm__device: cpu
  lgbm__boosting_type: goss
  lgbm__objective: binary
  lgbm__metric: auc
  lgbm__number_boosting_rounds: 100
  lgbm__early_stopping_rounds: 20
  lgbm__learning_rate: 0.1
  lgbm__max_bin: 500
  lgbm__max_depth: 12
  lgbm__num_leaves: 30
  lgbm__min_child_samples: 50
  lgbm__subsample: 1.0
  lgbm__subsample_freq: 1
  lgbm__colsample_bytree: 1.0
  lgbm__min_gain_to_split: 0.0
  lgbm__lambda_l1: 0.0
  lgbm__lambda_l2: 0.0
  lgbm__is_unbalanced: True
  lgbm__scale_pos_weight: 1.
  
# Catboost
  catboost__loss_function: Logloss
  catboost__eval_metric: AUC
  catboost__iterations: 50
  catboost__learning_rate: 0.05
  catboost__depth: 6
  catboost__l2_leaf_reg: 2
  catboost__border_count: 150 
  catboost__model_size_reg: 0.5
  catboost__colsample_bylevel: 1.0
  catboost__max_ctr_complexity: 1
  catboost__od_type: 'Iter'
  catboost__od_wait: 30 

# XGBoost
  xgb__booster: gbtree
  xgb__tree_method: exact # gpu_hist  # auto  hist
  xgb__objective: binary:logistic
  xgb__eval_metric: auc
  xgb__nrounds: 500
  xgb__early_stopping_rounds: 50
  xgb__eta: 0.1
  xgb__max_leaves: 4
  xgb__max_depth: 2
  xgb__max_bin: 300
  xgb__subsample: 0.8
  xgb__colsample_bylevel: 1
  xgb__min_child_weight: 3
  xgb__lambda: 2
  xgb__alpha: 10
  xgb__scale_pos_weight: 60.7

# Neural Network
  nn__layers: 2
  nn__neurons: '[16, 1]'
  nn__activation: '["relu", "sigmoid"]'
  nn__dropout: '[0., 0.]'
  nn__batch_norm: '[True, False]'
  nn__l1: '[0., 0.]'
  nn__l2: '[0., 0.]'
  nn__learning_rate: 0.01
  nn__beta_1: 0.9
  nn__beta_2: 0.99
  nn__epochs: 10
  nn__batch_size: 32

# Random forest
  rf__n_estimators: 50
  rf__criterion: gini
  rf__max_features: 1
  rf__max_depth: 20
  rf__min_samples_split: 10
  rf__min_samples_leaf: 10 
  rf__max_leaf_nodes: 3 
  rf__class_weight: balanced

# Logistic regression
  lr__penalty: l2
  lr__tol: 1e-4
  lr__C: 0.5
  lr__fit_intercept: True
  lr__class_weight: balanced
  lr__solver: saga
  lr__max_iter: 100

# SVC
  svc__kernel: rbf
  svc__C: 1
  svc__degree: 5
  svc__gamma: auto
  svc__coef0: 0.0
  svc__probability: True
  svc__tol: 1e-4
  svc__max_iter: -1

# Naive Bayes
  nb__alpha: 1
  nb__binarize: 0